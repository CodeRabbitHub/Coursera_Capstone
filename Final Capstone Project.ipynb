{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM Data Science Capstone - Battle of neighbourhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing First. Importing all the libraries that we will be using in notebook for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to handle data in a vectorized manner\n",
    "import numpy as np \n",
    "\n",
    "# library to handle data frames\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# library for data analsysis\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# library to handle JSON files\n",
    "import json \n",
    "\n",
    "# convert an address into latitude and longitude values\n",
    "from geopy.geocoders import Nominatim \n",
    "\n",
    "# library to handle requests\n",
    "import requests\n",
    "\n",
    "# tranform JSON file into a pandas dataframe\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# import folium map rendering library\n",
    "import folium \n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the wikpedia link in variable called URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/Template:Neighbourhoods_of_Chennai'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(URL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using beautiful soup to scrape data from wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text,'lxml')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the table in which all the neighbourhood names are stored and extracting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = soup.find('div',{\"style\":\"padding:0em 0.25em\"})\n",
    "print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul = td.find('ul')\n",
    "print(ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_li = ul.find_all('li')\n",
    "print(all_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in all_li:\n",
    "    print(li.a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the neighbourhoods name list in to a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neigh = [li.a.string for li in all_li]\n",
    "Neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Neighbourhood':Neigh})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for geographical coordinates of chennai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Chennai'\n",
    "\n",
    "geolocator = Nominatim(user_agent = 'Capstone_Project')\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Chennai are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering all the location latitudes and longitudes from OpenStreetMap API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords_local(neighbourhood, output_as='center'):\n",
    "    \n",
    "    \"\"\"\n",
    "    get the bounding box of a locality in WGS84 given its name\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    neighbourhood : str\n",
    "        name of the city in english and lowercase\n",
    "    output_as : 'str\n",
    "        chose from 'boundingbox' or 'center'. \n",
    "         - 'boundingbox' for [latmin, latmax, lonmin, lonmax]\n",
    "         - 'center' for [latcenter, loncenter]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : list\n",
    "        list with coordinates as str\n",
    "    \"\"\"\n",
    "    # create url\n",
    "    url = '{0}{1}{2}'.format('http://nominatim.openstreetmap.org/search.php?q=',\n",
    "                             neighbourhood+', Chennai, Tamilnadu',\n",
    "                             '&format=json&polygon=0')\n",
    "    \n",
    "    if requests.get(url).json():\n",
    "        response = requests.get(url).json()[0]\n",
    "    # parse response to list\n",
    "        if output_as == 'boundingbox':\n",
    "            lst = response[output_as]\n",
    "            output = [float(i) for i in lst]\n",
    "            print(output)\n",
    "        if output_as == 'center':\n",
    "            lst = [response.get(key) for key in ['lat','lon']]\n",
    "            output = [float(i) for i in lst]\n",
    "            print(output)\n",
    "        return output\n",
    "    else:\n",
    "        return [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "latitudeCln = []\n",
    "longitudeCln = []\n",
    "for index, row in df2.iterrows():\n",
    "    print(row[0])\n",
    "    response = get_coords_local(neighbourhood=row[0], output_as='center') \n",
    "    if response != False:\n",
    "        lat, long = response\n",
    "        latitudeCln.append(lat)\n",
    "        longitudeCln.append(long)\n",
    "\n",
    "df2['Latitude'] = latitudeCln\n",
    "df2['Longitude'] = longitudeCln\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe with Neighbourhood names and Location data. Let's drop the Neighbourhoods whose data is not avaliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2.Latitude != 0].reset_index(drop=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the above dataframe into a csv file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('Neighbourhoods.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now map all the neighbourhoods onto map using folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chennai = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(df3['Latitude'], df3['Longitude'], df3['Neighbourhood']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_chennai)  \n",
    "    \n",
    "map_chennai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'OLN1BAQQBHO234LKFIU1ZNGV4Z3O3P1GS5KIMTNPJHLX1MKL' # your Foursquare ID\n",
    "CLIENT_SECRET = 'VDM5CGGVSUOGKMY21ETO4J1UAJH5QJEALQCJAIWUF2DJXR2T' # your Foursquare Secret\n",
    "VERSION = '20190201' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for venues of one of the neighbourhood 'Adyar', The first one in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[0, 'Neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_latitude = df3.loc[0, 'Latitude'] # neighbourhood latitude value\n",
    "neighbourhood_longitude = df3.loc[0, 'Longitude'] # neighbourhood longitude value\n",
    "\n",
    "neighbourhood_name = df3.loc[0, 'Neighbourhood'] # neighbourhood name\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(neighbourhood_name, \n",
    "                                                               neighbourhood_latitude, \n",
    "                                                               neighbourhood_longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100\n",
    "radius = 500\n",
    "\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    neighbourhood_latitude, \n",
    "    neighbourhood_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching results in json form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the category type of venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to call to fetch the same data for all the nighbourhoods and appending them to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighbourhood', \n",
    "                  'Neighbourhood Latitude', \n",
    "                  'Neighbourhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_venues = getNearbyVenues(names=df3['Neighbourhood'],\n",
    "                                   latitudes=df3['Latitude'],\n",
    "                                   longitudes=df3['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chennai_venues.shape)\n",
    "chennai_venues.head()\n",
    "\n",
    "\n",
    "chennai_venues.to_csv('Chennai_Venues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping all the venues in neighbourhood and getiing the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_venues.groupby('Neighbourhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(chennai_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_onehot = pd.get_dummies(chennai_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "chennai_onehot['Neighbourhood'] = chennai_venues['Neighbourhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [chennai_onehot.columns[-1]] + list(chennai_onehot.columns[:-1])\n",
    "chennai_onehot = chennai_onehot[fixed_columns]\n",
    "\n",
    "chennai_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_grouped = chennai_onehot.groupby('Neighbourhood').mean().reset_index()\n",
    "chennai_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of categorial venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in chennai_grouped['Neighbourhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = chennai_grouped[chennai_grouped['Neighbourhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 venues in neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighbourhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighbourhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighbourhoods_venues_sorted['Neighbourhood'] = chennai_grouped['Neighbourhood']\n",
    "\n",
    "for ind in np.arange(chennai_grouped.shape[0]):\n",
    "    neighbourhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(chennai_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighbourhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means clustering with 5 clusters to segment neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusters = 5\n",
    "\n",
    "chennai_grouped_clustering = chennai_grouped.drop('Neighbourhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(chennai_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "neighbourhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add clustering labels\n",
    "# neighbourhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "chennai_merged = df3\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "chennai_merged = chennai_merged.join(neighbourhoods_venues_sorted.set_index('Neighbourhood'), on='Neighbourhood')\n",
    "\n",
    "chennai_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the NaN values from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged = chennai_merged.dropna()\n",
    "chennai_merged = chennai_merged.reset_index(drop=True)\n",
    "chennai_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged[\"Cluster Labels\"] = chennai_merged['Cluster Labels'].astype('int')\n",
    "chennai_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping clusters onto map of Chennai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(chennai_merged['Latitude'], chennai_merged['Longitude'], chennai_merged['Neighbourhood'], chennai_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring all the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged.loc[chennai_merged['Cluster Labels'] == 0, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged.loc[chennai_merged['Cluster Labels'] == 1, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged.loc[chennai_merged['Cluster Labels'] == 2, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged.loc[chennai_merged['Cluster Labels'] == 3, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_merged.loc[chennai_merged['Cluster Labels'] == 4, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaming_Venues = chennai_merged.loc[chennai_merged['Cluster Labels'] == 2, chennai_merged.columns[[0] + list(range(1, chennai_merged.shape[1]))]].reset_index(drop=True)\n",
    "Gaming_Venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Neighbourhoods to open gaming cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaming_data = Gaming_Venues[['Neighbourhood','Latitude','Longitude']]\n",
    "Gaming_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=5000, categoryIds='',LIMIT = 100):\n",
    "    try:\n",
    "        venues_list=[]\n",
    "        for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "            #print(name)\n",
    "\n",
    "            # create the API request URL\n",
    "            url = 'https://api.foursquare.com/v2/venues/search?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, VERSION, lat, lng, radius, LIMIT)\n",
    "\n",
    "            if (categoryIds != ''):\n",
    "                url = url + '&categoryId={}'\n",
    "                url = url.format(categoryIds)\n",
    "\n",
    "            # make the GET request\n",
    "            response = requests.get(url).json()\n",
    "            results = response[\"response\"]['venues']\n",
    "\n",
    "            # return only relevant information for each nearby venue\n",
    "            for v in results:\n",
    "                success = False\n",
    "                try:\n",
    "                    category = v['categories'][0]['name']\n",
    "                    success = True\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                if success:\n",
    "                    venues_list.append([(\n",
    "                        name, \n",
    "                        lat, \n",
    "                        lng, \n",
    "                        v['name'], \n",
    "                        v['location']['lat'], \n",
    "                        v['location']['lng'],\n",
    "                        v['categories'][0]['name']\n",
    "                    )])\n",
    "\n",
    "        nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "        nearby_venues.columns = ['Neighbourhood', \n",
    "                  'Neighbourhood Latitude', \n",
    "                  'Neighbourhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        print(url)\n",
    "        print(response)\n",
    "        print(results)\n",
    "        print(nearby_venues)\n",
    "\n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching all the school venues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_venues = getNearbyVenues(names=Gaming_data['Neighbourhood'], latitudes=Gaming_data['Latitude'], longitudes=Gaming_data['Longitude'], radius=2000, categoryIds='4bf58dd8d48988d13b941735')\n",
    "school_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_venues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping all the Schools onto the chennai Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToMap(df, color, existingMap):\n",
    "    for lat, lng, local, venue, venueCat in zip(df['Venue Latitude'], df['Venue Longitude'], df['Neighbourhood'], df['Venue'], df['Venue Category']):\n",
    "        label = '{} ({}) - {}'.format(venue, venueCat, local)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5,\n",
    "            popup=label,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7).add_to(existingMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chennai_schools = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "addToMap(school_venues, 'red', map_chennai_schools)\n",
    "map_chennai_schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriving all the colleges in the required neighbourhood and mapping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_venues = getNearbyVenues(names=Gaming_data['Neighbourhood'], latitudes=Gaming_data['Latitude'], longitudes=Gaming_data['Longitude'], radius=2000, categoryIds='4d4b7105d754a06372d81259')\n",
    "college_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_college_venues = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "addToMap(college_venues, 'green', map_college_venues)\n",
    "map_college_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Existing Gaming Cafes in Chennai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaming_cafe_venues = getNearbyVenues(names=Gaming_data['Neighbourhood'], latitudes=Gaming_data['Latitude'], longitudes=Gaming_data['Longitude'], radius=2000, categoryIds='4bf58dd8d48988d18d941735')\n",
    "Gaming_cafe_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_Gaming_cafe_venues = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "addToMap(Gaming_cafe_venues, 'green', map_Gaming_cafe_venues)\n",
    "map_Gaming_cafe_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumn(startDf, columnTitle, dataDf):\n",
    "    grouped = dataDf.groupby('Neighbourhood').count()\n",
    "    \n",
    "    for n in startDf['Neighbourhood']:\n",
    "        try:\n",
    "            startDf.loc[startDf['Neighbourhood'] == n,columnTitle] = grouped.loc[n, 'Venue']\n",
    "        except:\n",
    "            startDf.loc[startDf['Neighbourhood'] == n,columnTitle] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = Gaming_data.copy()\n",
    "addColumn(df_data, 'Gaming_Cafe', Gaming_cafe_venues)\n",
    "addColumn(df_data, 'Schools', school_venues)\n",
    "addColumn(df_data, 'Universities', college_venues)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing some of the Data in data frame (Schools and Universities Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# standardise the means to 0 and standard error to 1\n",
    "for i in df_data.columns[4:6]: # df.columns[:-1] = dataframe for all features\n",
    "    df_data[i] = preprocessing.scale(df_data[i].astype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frame Containing Neighbouthoods, Gaming cafe's, Schools and Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atttaching some weights to attribute and calculation Final Score\n",
    "\n",
    "weight_Gaming_cafe = -1\n",
    "\n",
    "weight_schools = 1\n",
    "\n",
    "weight_universities = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted = df_data[['Neighbourhood']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted['Score'] = df_data['Gaming_Cafe'] * weight_Gaming_cafe + df_data['Schools'] * weight_schools + df_data['Universities'] * weight_universities\n",
    "df_weighted = df_weighted.sort_values(by=['Score'], ascending=False)\n",
    "df_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mylapore is the best place to Opening a gaming Cafe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
